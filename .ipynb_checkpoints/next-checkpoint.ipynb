{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'open', u'high', u'low', u'volume', u'close'], dtype='object')\n",
      "5\n",
      "[  87.878   87.889   87.863  543.      87.874]\n",
      "21\n",
      "215595\n",
      "215574\n",
      "(215574, 21, 5)\n",
      "('X_train', (194017, 20, 5))\n",
      "('y_train', (194017,))\n",
      "('X_testdfrvgrr ', (21557, 20, 5))\n",
      "('y_test', (21557,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/ipython@5/5.5.0/libexec/vendor/lib/python2.7/site-packages/ipykernel_launcher.py:108: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/usr/local/Cellar/ipython@5/5.5.0/libexec/vendor/lib/python2.7/site-packages/ipykernel_launcher.py:108: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=20, return_sequences=True, input_shape=(None, 5))`\n",
      "/usr/local/Cellar/ipython@5/5.5.0/libexec/vendor/lib/python2.7/site-packages/ipykernel_launcher.py:117: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "/usr/local/lib/python2.7/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compilation Time : ', 0.03876018524169922)\n",
      "Train on 174615 samples, validate on 19402 samples\n",
      "Epoch 1/300\n",
      " - 41s - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0523 - val_acc: 0.0000e+00\n",
      "Epoch 2/300\n",
      " - 38s - loss: 0.0107 - acc: 0.0000e+00 - val_loss: 0.1372 - val_acc: 0.0000e+00\n",
      "Epoch 3/300\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt2\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import pickle\n",
    "\n",
    "df = pd.read_csv('modified_stock.csv')\n",
    "\n",
    "# df=df.values\n",
    "# X=df[:,:-1]\n",
    "# y=df[:,-1]\n",
    "# print y\n",
    "#\n",
    "#\n",
    "# model=BaggingRegressor(verbose=2,n_estimators=1000000)\n",
    "# model.fit(X,y)\n",
    "#\n",
    "#\n",
    "# # Dump the trained decision tree classifier with Pickle\n",
    "# decision_tree_pkl_filename = 'decision_tree_classifier_20170212.pkl'\n",
    "# # Open the file to save as pkl file\n",
    "# decision_tree_model_pkl = open(decision_tree_pkl_filename, 'wb')\n",
    "# pickle.dump(model, decision_tree_model_pkl)\n",
    "# # Close the pickle instances\n",
    "# decision_tree_model_pkl.close()\n",
    "\n",
    "# X=df[:,:-1]\n",
    "# y=df[:,-1].values\n",
    "# print y\n",
    "# print X\n",
    "# #\n",
    "# # print df[:: -1]\n",
    "\n",
    "def standard_scaler(X_train, X_test):\n",
    "    train_samples, train_nx, train_ny = X_train.shape\n",
    "    test_samples, test_nx, test_ny = X_test.shape\n",
    "\n",
    "    X_train = X_train.reshape((train_samples, train_nx * train_ny))\n",
    "    X_test = X_test.reshape((test_samples, test_nx * test_ny))\n",
    "\n",
    "    preprocessor = prep.StandardScaler().fit(X_train)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    X_train = X_train.reshape((train_samples, train_nx, train_ny))\n",
    "    X_test = X_test.reshape((test_samples, test_nx, test_ny))\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def preprocess_data(stock, seq_len):\n",
    "    amount_of_features = len(stock.columns)\n",
    "    print stock.columns\n",
    "    print amount_of_features\n",
    "\n",
    "    data = stock.as_matrix()\n",
    "    print data[0]\n",
    "\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    print sequence_length\n",
    "\n",
    "    print len(data)\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        # print data[index: index + sequence_length]\n",
    "\n",
    "        result.append(data[index: index + sequence_length])\n",
    "\n",
    "    print len(result)\n",
    "    result = np.array(result)\n",
    "    # print result\n",
    "\n",
    "\n",
    "    print result.shape\n",
    "    row = round(0.9 * result.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "    train = result[: int(row), :]\n",
    "\n",
    "    train, result = standard_scaler(train, result)\n",
    "\n",
    "    X_train = train[:, : -1]\n",
    "\n",
    "    y_train = train[:, -1][:, -1]\n",
    "\n",
    "    X_test = result[int(row):, : -1]\n",
    "    y_test = result[int(row):, -1][:, -1]\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], amount_of_features))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], amount_of_features))\n",
    "\n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # By setting return_sequences to True we are able to stack another LSTM layer\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "    print(\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "#\n",
    "window = 20\n",
    "X_train, y_train, X_test, y_test = preprocess_data(df[:: -1], window)\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print(\"X_testdfrvgrr \", X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "print(\"y_test\", y_test.shape)\n",
    "\n",
    "model = build_model([X_train.shape[2], window, 100, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=768,\n",
    "    nb_epoch=300,\n",
    "    validation_split=0.1,\n",
    "    verbose=2)\n",
    "\n",
    "trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "\n",
    "testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "# serialize model to json\n",
    "model_json = model.to_json()\n",
    "with open(\"model133.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model133.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "trainPredict = model.predict(X_test[1:20])\n",
    "print trainPredict\n",
    "\n",
    "diff = []\n",
    "ratio = []\n",
    "pred = model.predict(X_test[1:5])\n",
    "for u in range(len(y_test[1:5])):\n",
    "    pr = pred[u][0]\n",
    "    ratio.append((y_test[u] / pr) - 1)\n",
    "    diff.append(abs(y_test[u] - pr))\n",
    "\n",
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(pred, color='red', label='Prediction')\n",
    "plt2.plot(y_test[1:5], color='blue', label='Ground Truth')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
